{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle版本：2.0.1\n",
      "paddlehub版本：2.0.4\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import paddlehub as hub\r\n",
    "\r\n",
    "# 打印paddle、paddlehub版本信息\r\n",
    "print('paddle版本：' + paddle.__version__)\r\n",
    "print('paddlehub版本：' + hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压数据集\r\n",
    "!tar -xf /home/aistudio/data/data16287/thu_news.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_a\tlabel\r\n",
      "直击特里勾手助小牛反超神鸟发威火箭仍处劣势　　新浪体育讯　北京时间4月16日消息，火箭今天迎来常规赛的收官战。客场挑战达拉斯小牛的比赛将关系到火箭队最终的排名，目前西部的竞争仍然非常激励。尤其是西部第二到第七的六支球队将在今天展开捉对厮杀的情况下，黄蜂、小牛、开拓者以及马刺都有可能是火箭队的下一个对手。以下为本场比赛的精彩瞬间——　　第四节比赛还剩下8分多钟，姚明重新回到场上，但是小牛队的霍里随后在右翼接队友传球后上演一记三分跳投，虽然身体动作已经变形，但是他仍然将球命中，随后基德在弧顶处的一记三分跳投帮助小牛终于将比分反超，火箭在进攻中直接打不开局面，而小牛更是利用特里空切后的一记勾手将比分反超至4分，包括库班在内的所有小牛现场球迷都站起来振臂高呼，而此时阿德尔曼还在场边低头深沉的思索中。　　比赛还剩下最后5分多钟，洛瑞带球突破中被小牛队员犯规，洛瑞来不及刹车让自己直接撞到了观众席上，右腿疼痛难忍的他脸都几乎变形，结果他两罚两中，火箭队还落后两分。随后，洛瑞将球直接传给此时已经回到场上的阿泰，野兽此时将球稳下，并没有急于进攻，随后他顺势将球塞给兰德里，神鸟利用对方站位空隙直接杀到篮下，上篮成功，火箭将比分终于追至80平。场上局面对于火箭来说绝对是不容有失。　　(sabrina)\t体育\r\n",
      "北京网购年消费额112亿元　　商报讯(记者吴文治)昨日，淘宝网发布的《2009-2010年度中国网购热门城市报告》显示，北京年度网购消费力达112.5亿元，与上海相差近62亿元，位列十大热门消费力城市第二位。此外，男性网购的消费金额高出女性，与“女性是网购主力军”的传统观念不符。　　淘宝公布的报告显示，中国网购消费力十大城市分别是上海、北京、深圳、杭州、广州、南京、苏州、天津、温州和宁波。主要集中在以江浙沪为主的长三角地区、以广深为主的珠三角地区和以北京为主的京津地区。北京年度网购112.5亿元的消费额，占国内城市网购消费额的5.6%。　　中国网购消费力十大城市的消费金额性别来源比例中，男性占比超过了女性。前者占比达到53.5%，后者则为46.5%。不过，在成交人数、成交笔数等关键数据上显示，女性消费者均高于男性。此外，在十大网购热门城市中，25岁-34岁的群体成为网购消费的主力军，占比达到62.49%。\t科技\r\n"
     ]
    }
   ],
   "source": [
    "# 打印验证集前三条数据\r\n",
    "!head -n 3 thu_news/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "事业测试：你工作易受他人干扰吗(图)　　独家撰稿：苑椿　心理测试征稿启事 欢迎关注新浪星座微博　　办公室永远是个龙蛇混杂、藏龙卧虎的地方，你永远不知道一张张面具底下会是怎样的脸庞，你是否还傻傻的对别人的话听之任之，完全搞乱了自己工作的步调？还是笃定的坚守阵地，从未被谣言动摇分毫？赶紧来测测看吧！　　(本测试仅供娱乐，非专业心理指导。)\t星座\r\n",
      "趣味测试：你怎么红红火火过春节(图)　　独家撰稿：岚　心理测试征稿启事 欢迎关注新浪星座微博　　红红火火过大年啦，每年的此时你都会如何度过呢？是跟家人爱人在一起还是跟朋友兄弟外出欢聚呢？亦或背起行囊远离嘈杂，无论如何，总会有一种适合你的方式，赶紧来测测看吧！　　(本测试仅供娱乐，非专业心理指导。)\t星座\r\n",
      "人际测试：你的人际磁场强大吗(图)　　独家撰稿：大智若笨　心理测试征稿启事　　如何在草木皆兵的office里脱颖而出，最好的办法不是到处抱怨也不是埋头工作，而是要加强自己的磁场，让周围的人都被你所感染，如此有影响力，你难道还怕自己不能夺人眼球吗。　　独家撰稿：大智若笨　心理测试征稿启事　　如何在草木皆兵的office里脱颖而出，最好的办法不是到处抱怨也不是埋头工作，而是要加强自己的磁场，让周围的人都被你所感染，如此有影响力，你难道还怕自己不能夺人眼球吗。\t星座\r\n"
     ]
    }
   ],
   "source": [
    "# 打印验证集后三条数据\r\n",
    "!tail -n 3 thu_news/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据加载\r\n",
    "import os, io, csv\r\n",
    "from paddlehub.datasets.base_nlp_dataset import InputExample, TextClassificationDataset\r\n",
    "\r\n",
    "class ThuNews(TextClassificationDataset):\r\n",
    "    def __init__(self, tokenizer, mode='train', max_seq_len=128):\r\n",
    "        if mode == 'train':\r\n",
    "            data_file = 'train.txt'\r\n",
    "        elif mode == 'test':\r\n",
    "            data_file = 'test.txt'\r\n",
    "        else:\r\n",
    "            data_file = 'valid.txt'\r\n",
    "        super(ThuNews, self).__init__(\r\n",
    "            base_path='thu_news',\r\n",
    "            data_file=data_file,\r\n",
    "            tokenizer=tokenizer,\r\n",
    "            max_seq_len=max_seq_len,\r\n",
    "            mode=mode,\r\n",
    "            is_file_with_header=True,\r\n",
    "            label_list=['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚'])\r\n",
    "\r\n",
    "    # 解析文本文件里的样本\r\n",
    "    def _read_file(self, input_file, is_file_with_header: bool = False):\r\n",
    "        if not os.path.exists(input_file):\r\n",
    "            raise RuntimeError(\"The file {} is not found.\".format(input_file))\r\n",
    "        else:\r\n",
    "            with io.open(input_file, \"r\", encoding=\"UTF-8\") as f:\r\n",
    "                reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\r\n",
    "                examples = []\r\n",
    "                seq_id = 0\r\n",
    "                header = next(reader) if is_file_with_header else None\r\n",
    "                for line in reader:\r\n",
    "                    example = InputExample(guid=seq_id, text_a=line[0], label=line[1])\r\n",
    "                    seq_id += 1\r\n",
    "                    examples.append(example)\r\n",
    "                return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-10 22:00:27,492] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "[2021-04-10 22:00:29,077] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# 模型加载\r\n",
    "model = hub.Module(name='ernie', task='seq-cls', num_classes=14)\r\n",
    "tokenizer = model.get_tokenizer()\r\n",
    "\r\n",
    "# 实例化数据集\r\n",
    "train_dataset = ThuNews(tokenizer, mode='train')\r\n",
    "dev_dataset = ThuNews(tokenizer, mode='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-10 22:02:49,863] [ WARNING] - PaddleHub model checkpoint not found, start from scratch...\n",
      "[2021-04-10 22:02:52,193] [   TRAIN] - Epoch=1/3, Step=10/282 loss=2.2308 acc=0.3281 lr=0.000050 step/sec=4.30 | ETA 00:03:16\n",
      "[2021-04-10 22:02:54,328] [   TRAIN] - Epoch=1/3, Step=20/282 loss=1.6098 acc=0.6031 lr=0.000050 step/sec=4.68 | ETA 00:03:08\n",
      "[2021-04-10 22:02:56,458] [   TRAIN] - Epoch=1/3, Step=30/282 loss=1.1604 acc=0.7406 lr=0.000050 step/sec=4.70 | ETA 00:03:05\n",
      "[2021-04-10 22:02:58,602] [   TRAIN] - Epoch=1/3, Step=40/282 loss=0.8269 acc=0.8187 lr=0.000050 step/sec=4.66 | ETA 00:03:04\n",
      "[2021-04-10 22:03:00,746] [   TRAIN] - Epoch=1/3, Step=50/282 loss=0.6280 acc=0.8313 lr=0.000050 step/sec=4.67 | ETA 00:03:04\n",
      "[2021-04-10 22:03:02,887] [   TRAIN] - Epoch=1/3, Step=60/282 loss=0.6334 acc=0.8375 lr=0.000050 step/sec=4.67 | ETA 00:03:03\n",
      "[2021-04-10 22:03:05,027] [   TRAIN] - Epoch=1/3, Step=70/282 loss=0.4970 acc=0.8750 lr=0.000050 step/sec=4.67 | ETA 00:03:03\n",
      "[2021-04-10 22:03:07,187] [   TRAIN] - Epoch=1/3, Step=80/282 loss=0.4844 acc=0.8750 lr=0.000050 step/sec=4.63 | ETA 00:03:03\n",
      "[2021-04-10 22:03:09,356] [   TRAIN] - Epoch=1/3, Step=90/282 loss=0.2787 acc=0.9406 lr=0.000050 step/sec=4.61 | ETA 00:03:03\n",
      "[2021-04-10 22:03:11,503] [   TRAIN] - Epoch=1/3, Step=100/282 loss=0.3737 acc=0.9000 lr=0.000050 step/sec=4.66 | ETA 00:03:03\n",
      "[2021-04-10 22:03:13,654] [   TRAIN] - Epoch=1/3, Step=110/282 loss=0.3006 acc=0.9313 lr=0.000050 step/sec=4.65 | ETA 00:03:02\n",
      "[2021-04-10 22:03:15,824] [   TRAIN] - Epoch=1/3, Step=120/282 loss=0.3751 acc=0.9000 lr=0.000050 step/sec=4.61 | ETA 00:03:03\n",
      "[2021-04-10 22:03:17,996] [   TRAIN] - Epoch=1/3, Step=130/282 loss=0.3141 acc=0.9062 lr=0.000050 step/sec=4.60 | ETA 00:03:03\n",
      "[2021-04-10 22:03:20,152] [   TRAIN] - Epoch=1/3, Step=140/282 loss=0.2281 acc=0.9469 lr=0.000050 step/sec=4.64 | ETA 00:03:03\n",
      "[2021-04-10 22:03:22,310] [   TRAIN] - Epoch=1/3, Step=150/282 loss=0.2958 acc=0.9219 lr=0.000050 step/sec=4.63 | ETA 00:03:02\n",
      "[2021-04-10 22:03:24,471] [   TRAIN] - Epoch=1/3, Step=160/282 loss=0.3233 acc=0.9156 lr=0.000050 step/sec=4.63 | ETA 00:03:02\n",
      "[2021-04-10 22:03:26,637] [   TRAIN] - Epoch=1/3, Step=170/282 loss=0.3278 acc=0.9062 lr=0.000050 step/sec=4.62 | ETA 00:03:02\n",
      "[2021-04-10 22:03:28,800] [   TRAIN] - Epoch=1/3, Step=180/282 loss=0.2743 acc=0.9344 lr=0.000050 step/sec=4.62 | ETA 00:03:02\n",
      "[2021-04-10 22:03:30,963] [   TRAIN] - Epoch=1/3, Step=190/282 loss=0.3262 acc=0.9125 lr=0.000050 step/sec=4.62 | ETA 00:03:02\n",
      "[2021-04-10 22:03:33,121] [   TRAIN] - Epoch=1/3, Step=200/282 loss=0.2420 acc=0.9281 lr=0.000050 step/sec=4.63 | ETA 00:03:02\n",
      "[2021-04-10 22:03:35,295] [   TRAIN] - Epoch=1/3, Step=210/282 loss=0.3036 acc=0.9219 lr=0.000050 step/sec=4.60 | ETA 00:03:03\n",
      "[2021-04-10 22:03:37,470] [   TRAIN] - Epoch=1/3, Step=220/282 loss=0.2777 acc=0.9156 lr=0.000050 step/sec=4.60 | ETA 00:03:03\n",
      "[2021-04-10 22:03:39,636] [   TRAIN] - Epoch=1/3, Step=230/282 loss=0.2896 acc=0.9156 lr=0.000050 step/sec=4.62 | ETA 00:03:03\n",
      "[2021-04-10 22:03:41,812] [   TRAIN] - Epoch=1/3, Step=240/282 loss=0.2780 acc=0.9250 lr=0.000050 step/sec=4.59 | ETA 00:03:03\n",
      "[2021-04-10 22:03:43,999] [   TRAIN] - Epoch=1/3, Step=250/282 loss=0.3104 acc=0.9000 lr=0.000050 step/sec=4.57 | ETA 00:03:03\n",
      "[2021-04-10 22:03:46,166] [   TRAIN] - Epoch=1/3, Step=260/282 loss=0.2204 acc=0.9406 lr=0.000050 step/sec=4.61 | ETA 00:03:03\n",
      "[2021-04-10 22:03:48,327] [   TRAIN] - Epoch=1/3, Step=270/282 loss=0.2504 acc=0.9313 lr=0.000050 step/sec=4.63 | ETA 00:03:03\n",
      "[2021-04-10 22:03:50,492] [   TRAIN] - Epoch=1/3, Step=280/282 loss=0.2753 acc=0.9187 lr=0.000050 step/sec=4.62 | ETA 00:03:03\n",
      "[2021-04-10 22:03:54,119] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - [Evaluation result] avg_acc=0.8900\n",
      "[2021-04-10 22:04:05,913] [    EVAL] - Saving best model to ckpt/best_model [best acc=0.8900]\n",
      "[2021-04-10 22:04:05,915] [    INFO] - Saving model checkpoint to ckpt/epoch_1\n",
      "[2021-04-10 22:04:20,071] [   TRAIN] - Epoch=2/3, Step=10/282 loss=0.1901 acc=0.9469 lr=0.000050 step/sec=0.41 | ETA 00:04:21\n",
      "[2021-04-10 22:04:22,229] [   TRAIN] - Epoch=2/3, Step=20/282 loss=0.1174 acc=0.9750 lr=0.000050 step/sec=4.63 | ETA 00:04:18\n",
      "[2021-04-10 22:04:24,393] [   TRAIN] - Epoch=2/3, Step=30/282 loss=0.1706 acc=0.9531 lr=0.000050 step/sec=4.62 | ETA 00:04:16\n",
      "[2021-04-10 22:04:26,561] [   TRAIN] - Epoch=2/3, Step=40/282 loss=0.2155 acc=0.9437 lr=0.000050 step/sec=4.61 | ETA 00:04:14\n",
      "[2021-04-10 22:04:28,740] [   TRAIN] - Epoch=2/3, Step=50/282 loss=0.1501 acc=0.9656 lr=0.000050 step/sec=4.59 | ETA 00:04:11\n",
      "[2021-04-10 22:04:30,918] [   TRAIN] - Epoch=2/3, Step=60/282 loss=0.1927 acc=0.9469 lr=0.000050 step/sec=4.59 | ETA 00:04:09\n",
      "[2021-04-10 22:04:33,079] [   TRAIN] - Epoch=2/3, Step=70/282 loss=0.1627 acc=0.9469 lr=0.000050 step/sec=4.63 | ETA 00:04:08\n",
      "[2021-04-10 22:04:35,247] [   TRAIN] - Epoch=2/3, Step=80/282 loss=0.1437 acc=0.9594 lr=0.000050 step/sec=4.61 | ETA 00:04:06\n",
      "[2021-04-10 22:04:37,434] [   TRAIN] - Epoch=2/3, Step=90/282 loss=0.1487 acc=0.9688 lr=0.000050 step/sec=4.57 | ETA 00:04:04\n",
      "[2021-04-10 22:04:39,602] [   TRAIN] - Epoch=2/3, Step=100/282 loss=0.1332 acc=0.9688 lr=0.000050 step/sec=4.61 | ETA 00:04:03\n",
      "[2021-04-10 22:04:41,793] [   TRAIN] - Epoch=2/3, Step=110/282 loss=0.1502 acc=0.9531 lr=0.000050 step/sec=4.56 | ETA 00:04:01\n",
      "[2021-04-10 22:04:43,979] [   TRAIN] - Epoch=2/3, Step=120/282 loss=0.1442 acc=0.9625 lr=0.000050 step/sec=4.58 | ETA 00:04:00\n",
      "[2021-04-10 22:04:46,162] [   TRAIN] - Epoch=2/3, Step=130/282 loss=0.1388 acc=0.9594 lr=0.000050 step/sec=4.58 | ETA 00:03:58\n",
      "[2021-04-10 22:04:48,357] [   TRAIN] - Epoch=2/3, Step=140/282 loss=0.1914 acc=0.9437 lr=0.000050 step/sec=4.55 | ETA 00:03:57\n",
      "[2021-04-10 22:04:50,555] [   TRAIN] - Epoch=2/3, Step=150/282 loss=0.1572 acc=0.9625 lr=0.000050 step/sec=4.55 | ETA 00:03:56\n",
      "[2021-04-10 22:04:52,744] [   TRAIN] - Epoch=2/3, Step=160/282 loss=0.1558 acc=0.9469 lr=0.000050 step/sec=4.57 | ETA 00:03:55\n",
      "[2021-04-10 22:04:54,932] [   TRAIN] - Epoch=2/3, Step=170/282 loss=0.1348 acc=0.9531 lr=0.000050 step/sec=4.57 | ETA 00:03:54\n",
      "[2021-04-10 22:04:57,112] [   TRAIN] - Epoch=2/3, Step=180/282 loss=0.1942 acc=0.9469 lr=0.000050 step/sec=4.59 | ETA 00:03:53\n",
      "[2021-04-10 22:04:59,290] [   TRAIN] - Epoch=2/3, Step=190/282 loss=0.1649 acc=0.9594 lr=0.000050 step/sec=4.59 | ETA 00:03:51\n",
      "[2021-04-10 22:05:01,470] [   TRAIN] - Epoch=2/3, Step=200/282 loss=0.2064 acc=0.9469 lr=0.000050 step/sec=4.59 | ETA 00:03:50\n",
      "[2021-04-10 22:05:03,664] [   TRAIN] - Epoch=2/3, Step=210/282 loss=0.1623 acc=0.9531 lr=0.000050 step/sec=4.56 | ETA 00:03:50\n",
      "[2021-04-10 22:05:05,871] [   TRAIN] - Epoch=2/3, Step=220/282 loss=0.2031 acc=0.9437 lr=0.000050 step/sec=4.53 | ETA 00:03:49\n",
      "[2021-04-10 22:05:08,053] [   TRAIN] - Epoch=2/3, Step=230/282 loss=0.2015 acc=0.9437 lr=0.000050 step/sec=4.58 | ETA 00:03:48\n",
      "[2021-04-10 22:05:10,228] [   TRAIN] - Epoch=2/3, Step=240/282 loss=0.1511 acc=0.9563 lr=0.000050 step/sec=4.60 | ETA 00:03:47\n",
      "[2021-04-10 22:05:12,410] [   TRAIN] - Epoch=2/3, Step=250/282 loss=0.1298 acc=0.9781 lr=0.000050 step/sec=4.58 | ETA 00:03:46\n",
      "[2021-04-10 22:05:14,608] [   TRAIN] - Epoch=2/3, Step=260/282 loss=0.1688 acc=0.9500 lr=0.000050 step/sec=4.55 | ETA 00:03:45\n",
      "[2021-04-10 22:05:16,806] [   TRAIN] - Epoch=2/3, Step=270/282 loss=0.1657 acc=0.9500 lr=0.000050 step/sec=4.55 | ETA 00:03:45\n",
      "[2021-04-10 22:05:18,987] [   TRAIN] - Epoch=2/3, Step=280/282 loss=0.2161 acc=0.9313 lr=0.000050 step/sec=4.59 | ETA 00:03:44\n",
      "[2021-04-10 22:05:22,641] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - [Evaluation result] avg_acc=0.9186\n",
      "[2021-04-10 22:05:45,241] [    EVAL] - Saving best model to ckpt/best_model [best acc=0.9186]\n",
      "[2021-04-10 22:05:45,244] [    INFO] - Saving model checkpoint to ckpt/epoch_2\n",
      "[2021-04-10 22:05:59,659] [   TRAIN] - Epoch=3/3, Step=10/282 loss=0.1208 acc=0.9781 lr=0.000050 step/sec=0.30 | ETA 00:04:39\n",
      "[2021-04-10 22:06:01,807] [   TRAIN] - Epoch=3/3, Step=20/282 loss=0.1135 acc=0.9750 lr=0.000050 step/sec=4.65 | ETA 00:04:38\n",
      "[2021-04-10 22:06:03,969] [   TRAIN] - Epoch=3/3, Step=30/282 loss=0.0762 acc=0.9812 lr=0.000050 step/sec=4.63 | ETA 00:04:36\n",
      "[2021-04-10 22:06:06,145] [   TRAIN] - Epoch=3/3, Step=40/282 loss=0.0698 acc=0.9875 lr=0.000050 step/sec=4.60 | ETA 00:04:34\n",
      "[2021-04-10 22:06:08,313] [   TRAIN] - Epoch=3/3, Step=50/282 loss=0.0743 acc=0.9844 lr=0.000050 step/sec=4.61 | ETA 00:04:33\n",
      "[2021-04-10 22:06:10,490] [   TRAIN] - Epoch=3/3, Step=60/282 loss=0.0950 acc=0.9781 lr=0.000050 step/sec=4.59 | ETA 00:04:32\n",
      "[2021-04-10 22:06:12,655] [   TRAIN] - Epoch=3/3, Step=70/282 loss=0.0654 acc=0.9781 lr=0.000050 step/sec=4.62 | ETA 00:04:30\n",
      "[2021-04-10 22:06:14,839] [   TRAIN] - Epoch=3/3, Step=80/282 loss=0.1035 acc=0.9719 lr=0.000050 step/sec=4.58 | ETA 00:04:29\n",
      "[2021-04-10 22:06:17,037] [   TRAIN] - Epoch=3/3, Step=90/282 loss=0.1040 acc=0.9656 lr=0.000050 step/sec=4.55 | ETA 00:04:27\n",
      "[2021-04-10 22:06:19,226] [   TRAIN] - Epoch=3/3, Step=100/282 loss=0.0606 acc=0.9844 lr=0.000050 step/sec=4.57 | ETA 00:04:26\n",
      "[2021-04-10 22:06:21,411] [   TRAIN] - Epoch=3/3, Step=110/282 loss=0.1239 acc=0.9688 lr=0.000050 step/sec=4.58 | ETA 00:04:25\n",
      "[2021-04-10 22:06:23,594] [   TRAIN] - Epoch=3/3, Step=120/282 loss=0.0610 acc=0.9844 lr=0.000050 step/sec=4.58 | ETA 00:04:24\n",
      "[2021-04-10 22:06:25,788] [   TRAIN] - Epoch=3/3, Step=130/282 loss=0.0650 acc=0.9812 lr=0.000050 step/sec=4.56 | ETA 00:04:23\n",
      "[2021-04-10 22:06:27,972] [   TRAIN] - Epoch=3/3, Step=140/282 loss=0.0742 acc=0.9812 lr=0.000050 step/sec=4.58 | ETA 00:04:22\n",
      "[2021-04-10 22:06:30,163] [   TRAIN] - Epoch=3/3, Step=150/282 loss=0.0421 acc=0.9906 lr=0.000050 step/sec=4.56 | ETA 00:04:21\n",
      "[2021-04-10 22:06:32,356] [   TRAIN] - Epoch=3/3, Step=160/282 loss=0.0717 acc=0.9812 lr=0.000050 step/sec=4.56 | ETA 00:04:19\n",
      "[2021-04-10 22:06:34,538] [   TRAIN] - Epoch=3/3, Step=170/282 loss=0.0455 acc=0.9875 lr=0.000050 step/sec=4.58 | ETA 00:04:18\n",
      "[2021-04-10 22:06:36,727] [   TRAIN] - Epoch=3/3, Step=180/282 loss=0.0809 acc=0.9812 lr=0.000050 step/sec=4.57 | ETA 00:04:17\n",
      "[2021-04-10 22:06:38,907] [   TRAIN] - Epoch=3/3, Step=190/282 loss=0.0816 acc=0.9656 lr=0.000050 step/sec=4.59 | ETA 00:04:16\n",
      "[2021-04-10 22:06:41,088] [   TRAIN] - Epoch=3/3, Step=200/282 loss=0.0675 acc=0.9781 lr=0.000050 step/sec=4.58 | ETA 00:04:16\n",
      "[2021-04-10 22:06:43,280] [   TRAIN] - Epoch=3/3, Step=210/282 loss=0.0488 acc=0.9906 lr=0.000050 step/sec=4.56 | ETA 00:04:15\n",
      "[2021-04-10 22:06:45,468] [   TRAIN] - Epoch=3/3, Step=220/282 loss=0.0998 acc=0.9781 lr=0.000050 step/sec=4.57 | ETA 00:04:14\n",
      "[2021-04-10 22:06:47,650] [   TRAIN] - Epoch=3/3, Step=230/282 loss=0.1043 acc=0.9656 lr=0.000050 step/sec=4.58 | ETA 00:04:13\n",
      "[2021-04-10 22:06:49,833] [   TRAIN] - Epoch=3/3, Step=240/282 loss=0.1009 acc=0.9750 lr=0.000050 step/sec=4.58 | ETA 00:04:12\n",
      "[2021-04-10 22:06:52,016] [   TRAIN] - Epoch=3/3, Step=250/282 loss=0.0633 acc=0.9812 lr=0.000050 step/sec=4.58 | ETA 00:04:11\n",
      "[2021-04-10 22:06:54,204] [   TRAIN] - Epoch=3/3, Step=260/282 loss=0.0947 acc=0.9750 lr=0.000050 step/sec=4.57 | ETA 00:04:10\n",
      "[2021-04-10 22:06:56,401] [   TRAIN] - Epoch=3/3, Step=270/282 loss=0.1261 acc=0.9625 lr=0.000050 step/sec=4.55 | ETA 00:04:10\n",
      "[2021-04-10 22:06:58,580] [   TRAIN] - Epoch=3/3, Step=280/282 loss=0.1290 acc=0.9688 lr=0.000050 step/sec=4.59 | ETA 00:04:09\n",
      "[2021-04-10 22:07:02,238] [    EVAL] - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - [Evaluation result] avg_acc=0.8971\n",
      "[2021-04-10 22:07:02,241] [    INFO] - Saving model checkpoint to ckpt/epoch_3\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\r\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=5e-5, parameters=model.parameters())\r\n",
    "trainer = hub.Trainer(model, optimizer, checkpoint_dir='ckpt', use_gpu=True)\r\n",
    "trainer.train(train_dataset, epochs=3, batch_size=32, eval_dataset=dev_dataset, save_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-10 22:11:50,643] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "[2021-04-10 22:11:55,282] [    INFO] - Loaded parameters from /home/aistudio/ckpt/best_model/model.pdparams\n",
      "[2021-04-10 22:11:55,362] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 昌平京基鹭府10月29日推别墅1200万套起享97折　　新浪房产讯(编辑郭彪)京基鹭府(论坛相册户型样板间点评地图搜索)售楼处位于昌平区京承高速北七家出口向西南公里路南。项目预计10月29日开盘，总价1200万元/套起，2012年年底入住。待售户型为联排户型面积为410-522平方米，独栋户型面积为938平方米，双拼户型面积为522平方米。　　京基鹭府项目位于昌平定泗路与东北路交界处。项目周边配套齐全，幼儿园：伊顿双语幼儿园、温莎双语幼儿园；中学：北师大亚太实验学校、潞河中学(北京市重点)；大学：王府语言学校、北京邮电大学、现代音乐学院；医院：王府中西医结合医院(三级甲等)、潞河医院、解放军263医院、安贞医院昌平分院；购物：龙德广场、中联万家商厦、世纪华联超市、瑰宝购物中心、家乐福超市；酒店：拉斐特城堡、鲍鱼岛；休闲娱乐设施：九华山庄、温都温泉度假村、小汤山疗养院、龙脉温泉度假村、小汤山文化广场、皇港高尔夫、高地高尔夫、北鸿高尔夫球场；银行：工商银行、建设银行、中国银行、北京农村商业银行；邮局：中国邮政储蓄；其它：北七家建材城、百安居建材超市、北七家镇武装部、北京宏翔鸿企业孵化基地等，享受便捷生活。 \t Lable: 房产\n",
      "Data: 尽管官方到今天也没有公布《使命召唤：现代战争2》的游戏详情，但《使命召唤：现代战争2》首部包含游戏画面的影片终于现身。虽然影片仅有短短不到20秒，但影片最后承诺大家将于美国时间5月24日NBA职业篮球东区决赛时将会揭露更多的游戏内容。　　这部只有18秒的广告片闪现了9个镜头，能够辨识的场景有直升机飞向海岛军事工事，有飞机场争夺战，有潜艇和水下工兵，有冰上乘具，以及其他的一些镜头。整体来看《现代战争2》很大可能仍旧与俄罗斯有关。　　片尾有一则预告：“May24th，EasternConferenceFinals”，这是什么？这是说当前美国NBA联赛东部总决赛的日期。原来这部视频是NBA季后赛奥兰多魔术对波士顿凯尔特人队时，TNT电视台播放的广告。 \t Lable: 游戏\n",
      "Data: 罗马锋王竟公然挑战两大旗帜拉涅利的球队到底错在哪　　记者张恺报道主场一球小胜副班长巴里无可吹捧，罗马占优也纯属正常，倒是托蒂罚失点球和前两号门将先后受伤(多尼以三号身份出场)更让人揪心。阵容规模扩大，反而表现不如上赛季，缺乏一流强队的色彩，这是所有球迷对罗马的印象。　　拉涅利说：“去年我们带着嫉妒之心看国米，今年我们也有了和国米同等的超级阵容，许多教练都想有罗马的球员。阵容广了，寻找队内平衡就难了，某些时段球员的互相排斥和跟从前相比的落差都正常。有好的一面，也有不好的一面，所幸，我们一直在说一支伟大的罗马，必胜的信念和够级别的阵容，我们有了。”拉涅利的总结由近一阶段困扰罗马的队内摩擦、个别球员闹意见要走人而发，本赛季技术层面强化的罗马一直没有上赛季反扑的面貌，内部变化值得球迷关注。 \t Lable: 体育\n",
      "Data: 新总督致力提高加拿大公立教育质量　　滑铁卢大学校长约翰斯顿先生于10月1日担任加拿大总督职务。约翰斯顿先生还曾任麦吉尔大学长，并曾在多伦多大学、女王大学和西安大略大学担任教学职位。　　约翰斯顿先生在就职演说中表示，要将加拿大建设成为一个“聪明与关爱的国度”。为实现这一目标，他提出三个支柱：支持并关爱家庭、儿童；鼓励学习与创造；提倡慈善和志愿者精神。他尤其强调要关爱并尊重教师，并通过公立教育使每个人的才智得到充分发展。 \t Lable: 教育\n"
     ]
    }
   ],
   "source": [
    "# 预测\r\n",
    "data = [\r\n",
    "    # 房产\r\n",
    "    [\"昌平京基鹭府10月29日推别墅1200万套起享97折　　新浪房产讯(编辑郭彪)京基鹭府(论坛相册户型样板间点评地图搜索)售楼处位于昌平区京承高速北七家出口向西南公里路南。项目预计10月29日开盘，总价1200万元/套起，2012年年底入住。待售户型为联排户型面积为410-522平方米，独栋户型面积为938平方米，双拼户型面积为522平方米。　　京基鹭府项目位于昌平定泗路与东北路交界处。项目周边配套齐全，幼儿园：伊顿双语幼儿园、温莎双语幼儿园；中学：北师大亚太实验学校、潞河中学(北京市重点)；大学：王府语言学校、北京邮电大学、现代音乐学院；医院：王府中西医结合医院(三级甲等)、潞河医院、解放军263医院、安贞医院昌平分院；购物：龙德广场、中联万家商厦、世纪华联超市、瑰宝购物中心、家乐福超市；酒店：拉斐特城堡、鲍鱼岛；休闲娱乐设施：九华山庄、温都温泉度假村、小汤山疗养院、龙脉温泉度假村、小汤山文化广场、皇港高尔夫、高地高尔夫、北鸿高尔夫球场；银行：工商银行、建设银行、中国银行、北京农村商业银行；邮局：中国邮政储蓄；其它：北七家建材城、百安居建材超市、北七家镇武装部、北京宏翔鸿企业孵化基地等，享受便捷生活。\"],\r\n",
    "    # 游戏\r\n",
    "    [\"尽管官方到今天也没有公布《使命召唤：现代战争2》的游戏详情，但《使命召唤：现代战争2》首部包含游戏画面的影片终于现身。虽然影片仅有短短不到20秒，但影片最后承诺大家将于美国时间5月24日NBA职业篮球东区决赛时将会揭露更多的游戏内容。　　这部只有18秒的广告片闪现了9个镜头，能够辨识的场景有直升机飞向海岛军事工事，有飞机场争夺战，有潜艇和水下工兵，有冰上乘具，以及其他的一些镜头。整体来看《现代战争2》很大可能仍旧与俄罗斯有关。　　片尾有一则预告：“May24th，EasternConferenceFinals”，这是什么？这是说当前美国NBA联赛东部总决赛的日期。原来这部视频是NBA季后赛奥兰多魔术对波士顿凯尔特人队时，TNT电视台播放的广告。\"],\r\n",
    "    # 体育\r\n",
    "    [\"罗马锋王竟公然挑战两大旗帜拉涅利的球队到底错在哪　　记者张恺报道主场一球小胜副班长巴里无可吹捧，罗马占优也纯属正常，倒是托蒂罚失点球和前两号门将先后受伤(多尼以三号身份出场)更让人揪心。阵容规模扩大，反而表现不如上赛季，缺乏一流强队的色彩，这是所有球迷对罗马的印象。　　拉涅利说：“去年我们带着嫉妒之心看国米，今年我们也有了和国米同等的超级阵容，许多教练都想有罗马的球员。阵容广了，寻找队内平衡就难了，某些时段球员的互相排斥和跟从前相比的落差都正常。有好的一面，也有不好的一面，所幸，我们一直在说一支伟大的罗马，必胜的信念和够级别的阵容，我们有了。”拉涅利的总结由近一阶段困扰罗马的队内摩擦、个别球员闹意见要走人而发，本赛季技术层面强化的罗马一直没有上赛季反扑的面貌，内部变化值得球迷关注。\"],\r\n",
    "    # 教育\r\n",
    "    [\"新总督致力提高加拿大公立教育质量　　滑铁卢大学校长约翰斯顿先生于10月1日担任加拿大总督职务。约翰斯顿先生还曾任麦吉尔大学长，并曾在多伦多大学、女王大学和西安大略大学担任教学职位。　　约翰斯顿先生在就职演说中表示，要将加拿大建设成为一个“聪明与关爱的国度”。为实现这一目标，他提出三个支柱：支持并关爱家庭、儿童；鼓励学习与创造；提倡慈善和志愿者精神。他尤其强调要关爱并尊重教师，并通过公立教育使每个人的才智得到充分发展。\"]\r\n",
    "]\r\n",
    "\r\n",
    "label_list=['体育', '科技', '社会', '娱乐', '股票', '房产', '教育', '时政', '财经', '星座', '游戏', '家居', '彩票', '时尚']\r\n",
    "label_map = { \r\n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\r\n",
    "}\r\n",
    "\r\n",
    "model = hub.Module(\r\n",
    "    name='ernie',\r\n",
    "    task='seq-cls',\r\n",
    "    load_checkpoint='./ckpt/best_model/model.pdparams',\r\n",
    "    label_map=label_map)\r\n",
    "results = model.predict(data, max_seq_len=128, batch_size=1, use_gpu=True)\r\n",
    "for idx, text in enumerate(data):\r\n",
    "    print('Data: {} \\t Lable: {}'.format(text[0], results[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
